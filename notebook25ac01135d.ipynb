{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:07:13.339946Z","iopub.execute_input":"2025-03-31T15:07:13.340397Z","iopub.status.idle":"2025-03-31T15:07:15.600218Z","shell.execute_reply.started":"2025-03-31T15:07:13.340362Z","shell.execute_reply":"2025-03-31T15:07:15.599486Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class AudioDeepfakeDataset(Dataset):\n    def __init__(self, root_dir, transform=None, target_sample_rate=16000, duration=3):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with 'real' and 'fake' subdirectories\n            transform (callable, optional): Optional transform to be applied\n            target_sample_rate (int): Target sample rate for audio files\n            duration (float): Duration in seconds to which audio will be trimmed/padded\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        self.target_sample_rate = target_sample_rate\n        self.duration = duration\n        self.samples = []\n        \n        # Walk through the directory structure\n        for label, folder in enumerate(['real', 'fake']):\n            folder_path = os.path.join(root_dir, folder)\n            if os.path.exists(folder_path):\n                for file in os.listdir(folder_path):\n                    if file.endswith('.wav'):\n                        self.samples.append({\n                            'path': os.path.join(folder_path, file),\n                            'label': label\n                        })\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        audio_path = self.samples[idx]['path']\n        label = self.samples[idx]['label']\n        \n        # Load audio file\n        try:\n            audio, sr = librosa.load(audio_path, sr=self.target_sample_rate)\n            \n            # Ensure consistent duration\n            target_length = int(self.duration * self.target_sample_rate)\n            if len(audio) > target_length:\n                audio = audio[:target_length]\n            else:\n                padding = target_length - len(audio)\n                audio = np.pad(audio, (0, padding), mode='constant')\n                \n            if self.transform:\n                audio = self.transform(audio)\n                \n            return torch.FloatTensor(audio), label\n            \n        except Exception as e:\n            print(f\"Error loading {audio_path}: {e}\")\n            return torch.zeros(int(self.duration * self.target_sample_rate)), label\n\n# Create datasets\ntrain_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training')\nval_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/validation')\ntest_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/testing')\n\n# Create data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:07:15.601170Z","iopub.execute_input":"2025-03-31T15:07:15.601536Z","iopub.status.idle":"2025-03-31T15:07:15.705695Z","shell.execute_reply.started":"2025-03-31T15:07:15.601513Z","shell.execute_reply":"2025-03-31T15:07:15.704975Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        self.downsample = downsample\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\n\nclass RawNet2(nn.Module):\n    def __init__(self, num_classes=2):\n        super(RawNet2, self).__init__()\n        \n        # Initial layers\n        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=3)\n        \n        # Residual blocks\n        self.layer1 = self._make_layer(64, 64, 3)\n        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n        \n        # Attention block\n        self.attention = nn.Sequential(\n            nn.Conv1d(512, 256, kernel_size=1),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Conv1d(256, 512, kernel_size=1),\n            nn.Softmax(dim=2)\n        )\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool1d(1)\n        self.fc = nn.Linear(512, num_classes)\n        \n    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n                nn.BatchNorm1d(out_channels)\n            )\n        layers = []\n        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        # Add channel dimension\n        x = x.unsqueeze(1)\n        \n        # Initial processing\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        # Residual blocks\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        # Attention\n        att = self.attention(x)\n        x = x * att\n        \n        # Pooling and classification\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:07:15.707527Z","iopub.execute_input":"2025-03-31T15:07:15.707909Z","iopub.status.idle":"2025-03-31T15:07:15.719987Z","shell.execute_reply.started":"2025-03-31T15:07:15.707859Z","shell.execute_reply":"2025-03-31T15:07:15.719001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Initialize model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = RawNet2(num_classes=2).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n\ntrain_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training')\nval_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/validation')\ntest_dataset = AudioDeepfakeDataset('/kaggle/input/the-fake-or-real-dataset/for-original/for-original/testing')\n\n# Create data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n# Training function\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n    best_val_loss = float('inf')\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        train_loss = running_loss / len(train_loader)\n        train_acc = correct / total\n        train_losses.append(train_loss)\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        val_loss = val_loss / len(val_loader)\n        val_acc = correct / total\n        val_losses.append(val_loss)\n        \n        scheduler.step(val_loss)\n        \n        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}')\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n    \n    return train_losses, val_losses\n\n# Train the model\ntrain_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:07:15.720868Z","iopub.execute_input":"2025-03-31T15:07:15.721168Z","iopub.status.idle":"2025-03-31T18:01:25.375520Z","shell.execute_reply.started":"2025-03-31T15:07:15.721146Z","shell.execute_reply":"2025-03-31T18:01:25.374546Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 944/944 [37:55<00:00,  2.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss: 0.1808, Acc: 0.9211 | Val Loss: 0.0994, Acc: 0.9661\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 944/944 [30:53<00:00,  1.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss: 0.0567, Acc: 0.9808 | Val Loss: 0.0544, Acc: 0.9857\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 944/944 [30:56<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss: 0.0289, Acc: 0.9906 | Val Loss: 0.0275, Acc: 0.9921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 944/944 [30:54<00:00,  1.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss: 0.0213, Acc: 0.9933 | Val Loss: 0.0287, Acc: 0.9909\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 944/944 [31:00<00:00,  1.97s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss: 0.0147, Acc: 0.9953 | Val Loss: 0.0132, Acc: 0.9969\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\n\n# Paths to the directories\nfake_dir = '/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/fake'\nreal_dir = '/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/real'\n\n# Count the number of files in each directory\nnum_fake_files = len(os.listdir(fake_dir))\nnum_real_files = len(os.listdir(real_dir))\n\nprint(f\"Number of files in 'fake' directory: {num_fake_files}\")\nprint(f\"Number of files in 'real' directory: {num_real_files}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T18:01:25.376540Z","iopub.execute_input":"2025-03-31T18:01:25.377075Z","iopub.status.idle":"2025-03-31T18:01:25.396417Z","shell.execute_reply.started":"2025-03-31T18:01:25.377038Z","shell.execute_reply":"2025-03-31T18:01:25.395590Z"}},"outputs":[{"name":"stdout","text":"Number of files in 'fake' directory: 26941\nNumber of files in 'real' directory: 26941\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nfrom torch.utils.data import Subset\nimport random\n\ndef evaluate_model_subset(model, test_loader, subset_size=50):\n    model.eval()\n    \n    # Set random seed for reproducibility\n    random.seed(42)\n    \n    # Get a random subset of indices\n    all_indices = list(range(len(test_loader.dataset)))\n    subset_indices = random.sample(all_indices, min(subset_size, len(all_indices)))\n    \n    # Create a subset dataloader\n    subset_dataset = Subset(test_loader.dataset, subset_indices)\n    subset_loader = DataLoader(subset_dataset, batch_size=test_loader.batch_size, shuffle=False)\n    \n    correct = 0\n    total = 0\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for inputs, labels in subset_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n    \n    accuracy = correct / total\n    f1 = f1_score(all_labels, all_preds)\n    \n    print(f'Test Accuracy : {accuracy:.4f}')\n\n    \n    # Plot confusion matrix\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    \n    \n    return accuracy, f1\n\n# Evaluate on exactly 50 samples\nprint(\"Evaluating trained model...\")\ntest_accuracy = evaluate_model_subset(model, test_loader, subset_size=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T18:19:07.580615Z","iopub.execute_input":"2025-03-31T18:19:07.580982Z","iopub.status.idle":"2025-03-31T18:19:08.563714Z","shell.execute_reply.started":"2025-03-31T18:19:07.580953Z","shell.execute_reply":"2025-03-31T18:19:08.562902Z"}},"outputs":[{"name":"stdout","text":"Evaluating trained model...\nTest Accuracy : 0.5800\n","output_type":"stream"}],"execution_count":21}]}